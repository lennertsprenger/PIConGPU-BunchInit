{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb61b395-541f-4985-81fc-96d60b1fbf45",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from numba import cuda, jit\n",
    "import numpy as np\n",
    "import openpmd_api as io\n",
    "import scipy.constants\n",
    "from scipy.ndimage import gaussian_filter\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab53ac8a-a684-4707-b9d0-f524b2697b17",
   "metadata": {},
   "source": [
    "## Things to do in the future\n",
    "\n",
    "* specify a cutoff, behind all fields are written as 0 instead of a small value e.g. 1e-10 * field_max\n",
    "* multi GPU / multi Node calculations  field size are limited by GPU memory size\n",
    "\n",
    "## Things to note\n",
    "* The Convolutional PML fields aren't changed, which might lead to unexpected simulations\n",
    "* Only use this initialization on the 0 timestep (for now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5116cf15-2267-4ec1-a49e-ba36acd56324",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# this cell is only required for testing the write proccess\n",
    "try:\n",
    "    del readSeries\n",
    "    print(\"del readSeries\")\n",
    "except:\n",
    "    pass\n",
    "try:\n",
    "    del writeSeries\n",
    "    print(\"del writeSereies\")\n",
    "except:\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7fa483f-bb3e-4cbd-9c59-609e82aed735",
   "metadata": {},
   "source": [
    "## Set path to checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6646086f-be87-4014-b985-bbca20213b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# you can use one checkpoint explicitly checkpoint_0.h5\n",
    "# or a time series with checkpoint_%T.h5\n",
    "# the warning can be ignored when using the explicit checkpoint, we want just a single file\n",
    "#path = \"/bigdata/hplsim/scratch/spreng88/runs/bigFieldWithoutInit23/simOutput/checkpoints/checkpoint_0.h5\"\n",
    "readFile = \"/bigdata/hplsim/scratch/spreng88/runs/old/restart/tmp_%T.h5\"\n",
    "outputFile = \"/bigdata/hplsim/scratch/spreng88/runs/restart/write_%T.h5\"\n",
    "#readFile = \"/bigdata/hplsim/production/wrobel45/PWFA-bunch-runs/033_vacuum_prop_small/simOutput/checkpoints/checkpoint_%T.h5\"\n",
    "#outputFile = \"/bigdata/hplsim/scratch/spreng88/runs/restart/test_%T.h5\"\n",
    "cuda.select_device(0)\n",
    "readSeries = io.Series(readFile, io.Access.read_only)\n",
    "writeSeries = io.Series(outputFile, io.Access.create)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d917d7d8-d715-401b-b0fb-f3eece853c1a",
   "metadata": {},
   "source": [
    "## General setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca29448d-bcba-4506-8b13-4b9914ef8306",
   "metadata": {},
   "outputs": [],
   "source": [
    "nth = 1             # only use every nth - particle (for faster calculation for tests)\n",
    "\n",
    "# chunk_size set later for now\n",
    "#chunk_size = [100, 100, 100]   # z, y, x\n",
    "\n",
    "# add field to iteration 0\n",
    "inputIteration = readSeries.iterations[0] \n",
    "outputIteration = writeSeries.iterations[0]\n",
    "\n",
    "# Read attributes of the simulation that might be needed later\n",
    "# Everything is calculated in PIConGPU units\n",
    "# For SI units: length_si = value_pic * unit_length\n",
    "cell_depth = inputIteration.get_attribute(\"cell_depth\")          # z\n",
    "cell_height = inputIteration.get_attribute(\"cell_height\")        # y\n",
    "cell_width = inputIteration.get_attribute(\"cell_width\")          # x\n",
    "\n",
    "unit_efield = inputIteration.get_attribute(\"unit_efield\")\n",
    "unit_bfield = inputIteration.get_attribute(\"unit_bfield\")\n",
    "unit_charge = inputIteration.get_attribute(\"unit_charge\")\n",
    "unit_mass = inputIteration.get_attribute(\"unit_mass\")\n",
    "unit_speed = inputIteration.get_attribute(\"unit_speed\")\n",
    "unit_length = inputIteration.get_attribute(\"unit_length\")\n",
    "unit_time = inputIteration.get_attribute(\"unit_time\")\n",
    "\n",
    "pi = scipy.constants.pi\n",
    "c = scipy.constants.c / unit_speed\n",
    "eps0 = inputIteration.get_attribute(\"eps0\")\n",
    "mue0 = inputIteration.get_attribute(\"mue0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cba1a52d-92ea-4f84-8966-389366bb9fa4",
   "metadata": {},
   "source": [
    "## Cuda functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db0ff10-91d1-4267-b1e9-c9d3ebfba29e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@cuda.jit(device=True)\n",
    "def particleV(px, py, pz, mass):\n",
    "    \"\"\"\n",
    "    calculate particle speed from momentum\n",
    "    \"\"\"\n",
    "    \n",
    "    m2p2 = math.sqrt( (mass)**2 + px**2 + py**2 + pz**2)\n",
    "    \n",
    "    vx = px / m2p2 * c\n",
    "    vy = py / m2p2 * c\n",
    "    vz = pz / m2p2 * c\n",
    "    \n",
    "    return vx, vy, vz\n",
    "\n",
    "\n",
    "@cuda.jit(device=True)\n",
    "def param1(rx,ry,rz, rqx,rqy,rqz, vx,vy,vz):\n",
    "    \"\"\"\n",
    "    calculate some parameters that could be reused\n",
    "    r: position of field calculation\n",
    "    rq: position of charge q at time t\n",
    "    rq_tr: position of charge at retarded time tr\n",
    "    \"\"\"\n",
    "    \n",
    "    #\n",
    "    # solution equation:\n",
    "    # dt = t - tr   = time - retarded_time\n",
    "    # r where we want the field\n",
    "    # rq position of charge\n",
    "    # |c*dt| = |r - (rq - v*dt)|\n",
    "    # solve for dt:\n",
    "    # => (c^2 - |v|^2) * dt^2 - 2(r*v - rq*v) * dt + 2 * r*rq - |r|^2 - |rq|^2\n",
    "    #\n",
    "    a = (c**2 - (vx**2 + vy**2 + vz**2))\n",
    "    b = -2 * ((rx-rqx)*vx + (ry-rqy)*vy + (rz-rqz)*vz)\n",
    "    d = 2 * (rx*rqx + ry*rqy + rz*rqz) - (rx**2 + ry**2 + rz**2) - (rqx**2 + rqy**2 + rqz**2)\n",
    "    dt = (-b + math.sqrt(b**2 - 4*a*d)) / (2*a)\n",
    "    \n",
    "    rq_trx = rqx - vx * dt\n",
    "    rq_try = rqy - vy * dt\n",
    "    rq_trz = rqz - vz * dt\n",
    "\n",
    "    dvx = rx - rq_trx\n",
    "    dvy = ry - rq_try\n",
    "    dvz = rz - rq_trz\n",
    "    \n",
    "    distance = math.sqrt(dvx**2 + dvy**2 + dvz**2)\n",
    "    \n",
    "    if distance == 0:\n",
    "        distance = -1\n",
    "    \n",
    "    #n =  distanceVec / distance\n",
    "    nx = dvx / distance\n",
    "    ny = dvy / distance\n",
    "    nz = dvz / distance\n",
    "    \n",
    "    return nx, ny, nz, distance, dvx, dvy, dvz #n, distance, distanceVec\n",
    "\n",
    "\n",
    "@cuda.jit(device=True)\n",
    "def retardedEFieldParallel(q, nx, ny, nz, distance, dvx, dvy, dvz, vx, vy, vz):\n",
    "    \"\"\"\n",
    "    field for one position\n",
    "    q: charge\n",
    "    nx, ny, nz: unit vector to retarded position\n",
    "    distance: distance to retarded position\n",
    "    dvx, dvy, dvz: distance Vector to retarded position\n",
    "    vx, vy, vz: velocity vector of the charge\n",
    "    \"\"\"\n",
    "    \n",
    "    if distance == -1:\n",
    "        nx = 1\n",
    "        ny = 0\n",
    "        xz = 0\n",
    "    \n",
    "    factor = q / (4 * pi * eps0)\n",
    "    \n",
    "    ux = c * nx - vx\n",
    "    uy = c * ny - vy\n",
    "    uz = c * nz - vz\n",
    "    \n",
    "\n",
    "    scalar = factor * distance / (dvx*ux + dvy*uy + dvz*uz)**3 * (c**2 - (vx**2 + vy**2 + vz**2))\n",
    "    \n",
    "    return  scalar * ux, scalar * uy, scalar * uz\n",
    "\n",
    "\n",
    "@cuda.jit(device=True)\n",
    "def returnFields(q, rx,rex,ry,rey,rz,rez, rqx,rqy,rqz, px,py,pz, mass):\n",
    "    \"\"\"calculate the fields for the position,\n",
    "    currently ignoring the offset between the grid corner and field points\n",
    "    because we will use smoothing in the end over the field anyway\"\"\"\n",
    "    \n",
    "    vx, vy, vz = particleV(px, py, pz, mass)\n",
    "    \n",
    "    ## E Field ------------------------------------------------------------\n",
    "    nx, ny, nz, distancez, dvx, dvy, dvz = param1(rx, ry, rz, rqx, rqy, rqz, vx,vy,vz)\n",
    "    ex, ey, ez = retardedEFieldParallel(q, nx, ny, nz, distancez, dvx, dvy, dvz , vx, vy, vz)\n",
    "\n",
    "    \n",
    "    ## B Field ------------------------------------------------------------\n",
    "    bx = ( ny * ez - nz * ey ) / c\n",
    "    by = ( nz * ex - nx * ez ) / c\n",
    "    bz = ( nx * ey - ny * ex ) / c\n",
    "    \n",
    "    return ex, ey, ez, bx, by, bz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "768327f3-e5ba-4e7a-b2d4-536cafb14301",
   "metadata": {},
   "outputs": [],
   "source": [
    "@cuda.jit\n",
    "def particleParallel(Ex,Ey,Ez, Bx,By,Bz, q_, rqx_,rqy_,rqz_, px_,py_,pz_, mass_, weighting_, xdim, ydim, zdim, particleCount, chunk_offset):\n",
    "    \"\"\"\n",
    "    calculate all particles in parallel, loop over every point in the field\n",
    "    \n",
    "    Ex,Ey,Ez E field where new field is added\n",
    "    Bx,By,Bz B -\"-\n",
    "    \n",
    "    _ is on all input arrays read from checkpoint \n",
    "    q_ array from checkpoint with charges\n",
    "    rq_ position data of particles\n",
    "    p_ momentum of particles\n",
    "    weighting_ macro particle weighting\n",
    "    \n",
    "    xdim, ydim, zdim length of dimension of Ex,Bx, ...\n",
    "    Ex/Bx need to be 1D for atomic add\n",
    "    \"\"\"\n",
    "    \n",
    "    tix = cuda.threadIdx.x\n",
    "    bix = cuda.blockIdx.x\n",
    "    bdx = cuda.blockDim.x\n",
    "    \n",
    "    index = tix + bix * bdx    # particle index\n",
    "    index = index\n",
    "    \n",
    "    if index < particleCount:\n",
    "    \n",
    "        q = q_[index] * weighting_[index]\n",
    "        rqx = rqx_[index] * cell_width\n",
    "        rqy = rqy_[index] * cell_height\n",
    "        rqz = rqz_[index] * cell_depth\n",
    "        px = px_[index]\n",
    "        py = py_[index]\n",
    "        pz = pz_[index]\n",
    "        mass = mass_[index] * weighting_[index]\n",
    "\n",
    "        for x in range(xdim):\n",
    "\n",
    "            rx = (x + chunk_offset[2]) * cell_width\n",
    "            rex = (x + chunk_offset[2] + 0.5) * cell_width\n",
    "\n",
    "            for y in range(ydim):\n",
    "\n",
    "                ry = (y + chunk_offset[1]) * cell_height\n",
    "                rey = (y + chunk_offset[1] + 0.5) * cell_height\n",
    "\n",
    "                for z in range(zdim):    \n",
    "                    \n",
    "                    rz = (z + chunk_offset[0]) * cell_depth\n",
    "                    rez = (z + chunk_offset[0] + 0.5) * cell_depth\n",
    "\n",
    "                    fieldIndex = x + y * xdim + z * xdim * ydim\n",
    "                    \n",
    "                    ex, ey, ez, bx, by, bz = returnFields(q, rx,rex,ry,rey,rz,rez, rqx,rqy,rqz, px,py,pz, mass)\n",
    "                    \n",
    "                    cuda.atomic.add(Ex, fieldIndex, ex * nth)\n",
    "                    cuda.atomic.add(Ey, fieldIndex, ey * nth)\n",
    "                    cuda.atomic.add(Ez, fieldIndex, ez * nth)\n",
    "\n",
    "                    cuda.atomic.add(Bx, fieldIndex, bx)\n",
    "                    cuda.atomic.add(By, fieldIndex, by)\n",
    "                    cuda.atomic.add(Bz, fieldIndex, bz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c3087f5-be7e-4461-b028-2f148653a3c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "@cuda.jit\n",
    "def FieldParallel(Ex,Ey,Ez, Bx,By,Bz, q_, rqx_,rqy_,rqz_, px_,py_,pz_, mass_, weighting_, xdim, ydim, zdim, particleCount, chunk_offset):\n",
    "    \"\"\"\n",
    "    Calculate all field points in parallel, loop over all particles\n",
    "    \n",
    "    Ex,Ey,Ez E field where new field is added\n",
    "    Bx,By,Bz B -\"-\n",
    "    \n",
    "    a trailing _ is on all input arrays read from checkpoint \n",
    "    q_ array from checkpoint with charges\n",
    "    rq_ position data of particles\n",
    "    p_ momentum of particles\n",
    "    \n",
    "    xdim, ydim, zdim length of dimension of Ex,Bx, ...\n",
    "    Ex/Bx need to be 1D for atomic add\n",
    "    \"\"\"\n",
    "    tix = cuda.threadIdx.x\n",
    "    bix = cuda.blockIdx.x\n",
    "    bdx = cuda.blockDim.x\n",
    "    \n",
    "    fieldIndex = tix + bix * bdx    # field index\n",
    "    \n",
    "    # calculate 3d coordinate from 1d field coordinate array\n",
    "    # fieldIndex = x + y * xdim + z * xdim * ydim\n",
    "    z = math.floor( fieldIndex / (xdim*ydim) )\n",
    "    y = math.floor( (fieldIndex - z * xdim*ydim) / xdim )\n",
    "    x = fieldIndex - z * xdim*ydim - y * xdim\n",
    "    \n",
    "    x = x + chunk_offset[2]\n",
    "    y = y + chunk_offset[1]\n",
    "    z = z + chunk_offset[0]\n",
    "    \n",
    "    if fieldIndex < xdim*ydim*zdim:\n",
    "        \n",
    "        #for index in range(particleCount):\n",
    "        # or add filter if you only want the field of some particles of that species\n",
    "        for index in range(particleCount):\n",
    "        \n",
    "            q = q_[index] * weighting_[index]\n",
    "            rqx = rqx_[index] * cell_width\n",
    "            rqy = rqy_[index] * cell_height\n",
    "            rqz = rqz_[index] * cell_depth\n",
    "            px = px_[index]\n",
    "            py = py_[index]\n",
    "            pz = pz_[index]\n",
    "            mass = mass_[index] * weighting_[index]\n",
    "            \n",
    "            rx = x * cell_width\n",
    "            rex = (x + 0.5) * cell_width\n",
    "            \n",
    "            ry = y * cell_height\n",
    "            rey = (y + 0.5) * cell_height\n",
    "            \n",
    "            rz = z * cell_depth\n",
    "            rez = (z + 0.5) * cell_depth\n",
    "            \n",
    "            ex, ey, ez, bx, by, bz = returnFields(q, rx,rex,ry,rey,rz,rez, rqx,rqy,rqz, px,py,pz, mass)\n",
    "\n",
    "            cuda.atomic.add(Ex, fieldIndex, ex * nth)\n",
    "            cuda.atomic.add(Ey, fieldIndex, ey * nth)\n",
    "            cuda.atomic.add(Ez, fieldIndex, ez * nth)\n",
    "\n",
    "            cuda.atomic.add(Bx, fieldIndex, bx)\n",
    "            cuda.atomic.add(By, fieldIndex, by)\n",
    "            cuda.atomic.add(Bz, fieldIndex, bz)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b78dbe31-11bd-4fa7-a0a7-f7e878713505",
   "metadata": {},
   "outputs": [],
   "source": [
    "force_attribute_list = ['shape', 'position', 'axisLabels', 'gridGlobalOffset', 'gridSpacing']\n",
    "\n",
    "def copy_attributes(inputAtr, outputAtr):\n",
    "    dtypes = inputAtr.attribute_dtypes\n",
    "    for attribute in inputAtr.attributes:\n",
    "        attribute_value = inputAtr.get_attribute(attribute)\n",
    "        if attribute in force_attribute_list:\n",
    "            if type(attribute_value) != list:\n",
    "                attribute_value = [attribute_value]\n",
    "        outputAtr.set_attribute(attribute, attribute_value, dtypes[attribute])\n",
    "        \n",
    "def copy_series_attributes(inputAtr, outputAtr):\n",
    "    attributes_to_skip = ['openPMD', 'openPMDextension']\n",
    "    for attribute in inputAtr.attributes:\n",
    "        if attribute in attributes_to_skip:\n",
    "            continue\n",
    "        attribute_value = inputAtr.get_attribute(attribute)\n",
    "        outputAtr.set_attribute(attribute, attribute_value)\n",
    "        \n",
    "def print_attributes(atr):\n",
    "    try:\n",
    "        dtypes = atr.attribute_dtypes\n",
    "        for attribute in atr.attributes:\n",
    "            print(attribute, \":\", atr.get_attribute(attribute), \" - \", dtypes[attribute])\n",
    "        print()\n",
    "    except:\n",
    "        print('errro in print attributes')\n",
    "\n",
    "        \n",
    "        \n",
    "#### write mesh data ####\n",
    "\n",
    "def copy_mesh_container(input_mesh_container, output_mesh_container, exclude_mesh=[]):\n",
    "    copy_attributes(input_mesh_container, output_mesh_container)\n",
    "    \n",
    "    for mesh in input_mesh_container:\n",
    "        if mesh in exclude_mesh:\n",
    "            print(\"don't copy mesh:\", mesh)\n",
    "            continue\n",
    "        print('mesh:', mesh)\n",
    "        \n",
    "        input_mesh = input_mesh_container[mesh]\n",
    "        output_mesh = output_mesh_container[mesh]\n",
    "        \n",
    "        copy_mesh(input_mesh, output_mesh)\n",
    "        \n",
    "        writeSeries.flush()\n",
    "        \n",
    "    \n",
    "def copy_mesh(input_mesh, output_mesh):\n",
    "    copy_attributes(input_mesh, output_mesh)\n",
    "    \n",
    "    for mesh_record_component in input_mesh:\n",
    "        print('  mesh_record_component:', mesh_record_component)\n",
    "        \n",
    "        input_mesh_record_component = input_mesh[mesh_record_component]\n",
    "        output_mesh_record_component = output_mesh[mesh_record_component]\n",
    "        \n",
    "        copy_mesh_record_component(input_mesh_record_component, output_mesh_record_component)\n",
    "        \n",
    "    \n",
    "def copy_mesh_record_component(input_mesh_record_component, output_mesh_record_component):\n",
    "    copy_attributes(input_mesh_record_component, output_mesh_record_component)\n",
    "    \n",
    "    data_dtype = input_mesh_record_component.dtype\n",
    "    data_shape = input_mesh_record_component.shape\n",
    "    \n",
    "    dataset = io.Dataset(data_dtype, data_shape)\n",
    "    output_mesh_record_component.reset_dataset(dataset)\n",
    "    \n",
    "    data = input_mesh_record_component.load_chunk()\n",
    "    readSeries.flush()\n",
    "    \n",
    "    output_mesh_record_component.store_chunk(data)\n",
    "    \n",
    "    \n",
    "    \n",
    "#### write particle data ####\n",
    "\n",
    "def copy_particle_container(input_particle_container, output_particle_container):\n",
    "    copy_attributes(input_particle_container, output_particle_container)\n",
    "    \n",
    "    for particle_species in input_particle_container:\n",
    "        print('species:', particle_species)\n",
    "        \n",
    "        input_particle_species = input_particle_container[particle_species]\n",
    "        output_particle_species = output_particle_container[particle_species]\n",
    "        \n",
    "        copy_particle_species(input_particle_species, output_particle_species)\n",
    "\n",
    "        input_particle_patches = input_particle_species.particle_patches\n",
    "        output_particle_patches = output_particle_species.particle_patches\n",
    "        \n",
    "        copy_particle_patches(input_particle_patches, output_particle_patches)\n",
    "    \n",
    "    \n",
    "def copy_particle_species(input_particle_species, output_particle_species):\n",
    "    copy_attributes(input_particle_species, output_particle_species)\n",
    "    \n",
    "    for record in input_particle_species:\n",
    "        print('  record:', record)\n",
    "        \n",
    "        input_record = input_particle_species[record]\n",
    "        output_record = output_particle_species[record]\n",
    "        \n",
    "        copy_record(input_record, output_record)\n",
    "        \n",
    "        writeSeries.flush()\n",
    "\n",
    "        \n",
    "def copy_record(input_record, output_record):\n",
    "    copy_attributes(input_record, output_record)\n",
    "    \n",
    "    for record_component in input_record:\n",
    "        print('    record_component:', record_component)\n",
    "        \n",
    "        input_record_component = input_record[record_component]\n",
    "        output_record_component = output_record[record_component]\n",
    "        \n",
    "        copy_record_component(input_record_component, output_record_component)\n",
    "    \n",
    "\n",
    "def copy_record_component(input_record_component, output_record_component):\n",
    "    copy_attributes(input_record_component, output_record_component)\n",
    "    \n",
    "    is_constant = input_record_component.constant\n",
    "    \n",
    "    if is_constant:\n",
    "        value = input_record_component.get_attribute('value')\n",
    "        output_record_component.make_constant(value)\n",
    "        \n",
    "        return\n",
    "    \n",
    "    data_dtype = input_record_component.dtype\n",
    "    data_shape = input_record_component.shape\n",
    "    \n",
    "    dataset = io.Dataset(data_dtype, data_shape)\n",
    "    output_record_component.reset_dataset(dataset)\n",
    "    \n",
    "    data = input_record_component.load_chunk()\n",
    "    readSeries.flush()\n",
    "    \n",
    "    output_record_component.store_chunk(data)\n",
    "    \n",
    "\n",
    "\n",
    "#### write particle patch data ####\n",
    "\n",
    "def copy_particle_patches(input_particle_patches, output_particle_patches):\n",
    "    copy_attributes(input_particle_patches, output_particle_patches)\n",
    "    \n",
    "    for patch_record in input_particle_patches:\n",
    "        print('  patch_record:', patch_record)\n",
    "        \n",
    "        input_patch_record = input_particle_patches[patch_record]\n",
    "        output_patch_record = output_particle_patches[patch_record]\n",
    "        \n",
    "        copy_patch_record(input_patch_record, output_patch_record)\n",
    "        \n",
    "    writeSeries.flush()\n",
    "\n",
    "\n",
    "def copy_patch_record(input_patch_record, output_patch_record):\n",
    "    copy_attributes(input_patch_record, output_patch_record)\n",
    "    \n",
    "    for patch_record_component in input_patch_record:\n",
    "        print('    patch_record_component:', patch_record_component)\n",
    "        \n",
    "        input_patch_record_component = input_patch_record[patch_record_component]\n",
    "        output_patch_record_component = output_patch_record[patch_record_component]\n",
    "        \n",
    "        copy_patch_record_component(input_patch_record_component, output_patch_record_component)\n",
    "        \n",
    "\n",
    "def copy_patch_record_component(input_patch_record_component, output_patch_record_component):\n",
    "    copy_attributes(input_patch_record_component, output_patch_record_component)\n",
    "    \n",
    "    data_dtype = input_patch_record_component.dtype\n",
    "    data_shape = input_patch_record_component.shape\n",
    "    \n",
    "    dataset = io.Dataset(data_dtype, data_shape)\n",
    "    output_patch_record_component.reset_dataset(dataset)\n",
    "    \n",
    "    data = input_patch_record_component.load()\n",
    "    readSeries.flush()\n",
    "    \n",
    "    \n",
    "    for i in range(np.prod(data_shape)):\n",
    "        print('  ',i)\n",
    "        output_patch_record_component.store(i, data[i])\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "def write():\n",
    "    \n",
    "    global writeSeries\n",
    "    \n",
    "    inputIteration\n",
    "    \n",
    "    # copy particle data\n",
    "    input_particle_container = inputIteration.particles\n",
    "    output_particle_container = outputIteration.particles\n",
    "    \n",
    "    copy_particle_container(input_particle_container, output_particle_container)\n",
    "    \n",
    "    \n",
    "    # copy/write field data\n",
    "    input_mesh_container = inputIteration.meshes\n",
    "    output_mesh_container = outputIteration.meshes\n",
    "    \n",
    "    copy_mesh_container(input_mesh_container, output_mesh_container, exclude_mesh=['E', 'B'])\n",
    "    \n",
    "    del writeSeries\n",
    "    \n",
    "    \n",
    "def write_general_data():\n",
    "\n",
    "    # copy general attributes ----------------------------------\n",
    "    copy_series_attributes(readSeries, writeSeries)\n",
    "\n",
    "    copy_attributes(inputIteration, outputIteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c56c7b84-318a-4dad-b75f-d0b740d20f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "write_general_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b8a1a12-c07c-4882-8b3a-61c7c4dc2f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def smoothFields(ex, ey, ez, bx, by, bz, sigma):\n",
    "    ex = gaussian_filter(ex.reshape(zdim, ydim, xdim), sigma)\n",
    "    ey = gaussian_filter(ey.reshape(zdim, ydim, xdim), sigma)\n",
    "    ez = gaussian_filter(ez.reshape(zdim, ydim, xdim), sigma)\n",
    "    bx = gaussian_filter(bx.reshape(zdim, ydim, xdim), sigma)\n",
    "    by = gaussian_filter(by.reshape(zdim, ydim, xdim), sigma)\n",
    "    bz = gaussian_filter(bz.reshape(zdim, ydim, xdim), sigma)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17328d3e-644d-4182-b9d8-12bbdd87c016",
   "metadata": {},
   "source": [
    "## load particle data from the checkpoint\n",
    "define the species identifier string, as in the simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7952feba-32f4-4fab-a5c5-d7dd29dee239",
   "metadata": {},
   "outputs": [],
   "source": [
    "species = \"b\"\n",
    "\n",
    "xpos_incell = inputIteration.particles[species][\"position\"][\"x\"][:]\n",
    "ypos_incell = inputIteration.particles[species][\"position\"][\"y\"][:]\n",
    "zpos_incell = inputIteration.particles[species][\"position\"][\"z\"][:]\n",
    "xpos_offset = inputIteration.particles[species][\"positionOffset\"][\"x\"][:]\n",
    "ypos_offset = inputIteration.particles[species][\"positionOffset\"][\"y\"][:]\n",
    "zpos_offset = inputIteration.particles[species][\"positionOffset\"][\"z\"][:]\n",
    "momentumx = inputIteration.particles[species][\"momentum\"][\"x\"][:]\n",
    "momentumy = inputIteration.particles[species][\"momentum\"][\"y\"][:]\n",
    "momentumz = inputIteration.particles[species][\"momentum\"][\"z\"][:]\n",
    "weightings = inputIteration.particles[species][\"weighting\"][io.Record_Component.SCALAR][:]\n",
    "charge = inputIteration.particles[species][\"charge\"][io.Record_Component.SCALAR][:]\n",
    "mass = inputIteration.particles[species][\"mass\"][io.Record_Component.SCALAR][:]\n",
    "\n",
    "readSeries.flush()\n",
    "\n",
    "xpos = xpos_incell + np.float32(xpos_offset)\n",
    "ypos = ypos_incell + np.float32(ypos_offset)\n",
    "zpos = zpos_incell + np.float32(zpos_offset)\n",
    "\n",
    "# free some memory\n",
    "del xpos_incell, ypos_incell, zpos_incell\n",
    "del xpos_offset, ypos_offset, zpos_offset\n",
    "\n",
    "\n",
    "# use just every nth particle\n",
    "# needs to be in a new numpy array\n",
    "# because it must be continous in memory to be copied to gpu\n",
    "momentumx = np.array(momentumx[::nth])\n",
    "momentumy = np.array(momentumy[::nth])\n",
    "momentumz = np.array(momentumz[::nth])\n",
    "weightings = np.array(weightings[::nth])\n",
    "charge = np.array(charge[::nth])\n",
    "mass = np.array(mass[::nth])\n",
    "xpos = np.array(xpos[::nth])\n",
    "ypos = np.array(ypos[::nth])\n",
    "zpos = np.array(zpos[::nth])\n",
    "particleCount = len(mass)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80117bf6-b892-40ef-8f3d-5ee74a748a4f",
   "metadata": {},
   "source": [
    "## output to check particleCount and gridsize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba100d4d-b270-4ee3-9aa9-72fe0e089514",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"particleCount:\", particleCount)\n",
    "input_field_shape = inputIteration.meshes[\"E\"][\"x\"].shape\n",
    "xdim_total = input_field_shape[2]\n",
    "ydim_total = input_field_shape[1]\n",
    "zdim_total = input_field_shape[0]\n",
    "input_field_shape_total = xdim_total * ydim_total * zdim_total\n",
    "print(\"gridSize (z,y,x, total):\", input_field_shape, input_field_shape_total)\n",
    "\n",
    "field_dtype = inputIteration.meshes['E']['x'].dtype\n",
    "field_dataset = io.Dataset( field_dtype, input_field_shape)\n",
    "\n",
    "for field_name in ['E', 'B']:\n",
    "    copy_attributes(inputIteration.meshes[field_name], outputIteration.meshes[field_name])\n",
    "    for component in ['x', 'y', 'z']:\n",
    "        copy_attributes(inputIteration.meshes[field_name][component], outputIteration.meshes[field_name][component])\n",
    "        outputIteration.meshes[field_name][component].reset_dataset(field_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "734f1bdb-7922-42d0-a6c4-6a2c4e5132ea",
   "metadata": {},
   "source": [
    "## calculate the fields\n",
    "\n",
    "set the chunk_size to the number of cells if the gpu has enough memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2914a16e-be01-43ea-bff1-e9ee26dda1f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_size = np.array([768, 512, 768], dtype=np.int32)  # z y x\n",
    "xdim = chunk_size[2]\n",
    "ydim = chunk_size[1]\n",
    "zdim = chunk_size[0]\n",
    "shape = xdim * ydim * zdim\n",
    "\n",
    "min_memory_device = shape * 24 + particleCount * 56\n",
    "print(\"device needs a minimum memory of:\",min_memory_device, \"Bytes = {:.5} GB\".format(min_memory_device*1e-9))\n",
    "\n",
    "chunk_offset = np.array([0, 200, 0], dtype=np.int32)          # offset for chunk (z, y, z)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc4b5096-449f-4803-b064-ecf82ca02a93",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "if particleCount <= shape:    # maybe add a constant, but needs testing for optimal choise\n",
    "    # calculate every field position in parallel (loop over the particles)\n",
    "    # few particles, many field positions\n",
    "    blockdim = 256                                              # number of threads per block (multiple 32 for optimal speed)\n",
    "    griddim = math.ceil(shape / blockdim)                       # number of blocks in the grid\n",
    "    cudaFunc = FieldParallel\n",
    "    print(\"Fields in parallel\")\n",
    "    \n",
    "else:\n",
    "    # calculate every particle in parallel (loop over the entire field)\n",
    "    # many particles, few field positions\n",
    "    blockdim = 32  #256                                         # number of threads per block (multiple 32 for optimal speed)\n",
    "    griddim = math.ceil(particleCount / blockdim)         # number of blocks in the grid\n",
    "    cudaFunc = particleParallel\n",
    "    print(\"particles in parallel\")\n",
    "    \n",
    "print(\"particles to be processed:\", particleCount)\n",
    "\n",
    "# for test on a smaller number of particles\n",
    "#blockdim = 1\n",
    "#griddim = 1\n",
    "\n",
    "array_dtype = np.float32                            # dtype for arrays\n",
    "ex = np.zeros(shape, dtype=array_dtype)\n",
    "ey = np.zeros(shape, dtype=array_dtype)\n",
    "ez = np.zeros(shape, dtype=array_dtype)\n",
    "bx = np.zeros(shape, dtype=array_dtype)\n",
    "by = np.zeros(shape, dtype=array_dtype)\n",
    "bz = np.zeros(shape, dtype=array_dtype)\n",
    "\n",
    "fields = {}\n",
    "fields['E'] = {}\n",
    "fields['B'] = {}\n",
    "fields['E']['x'] = ex\n",
    "fields['E']['y'] = ey\n",
    "fields['E']['z'] = ez\n",
    "fields['B']['x'] = bx\n",
    "fields['B']['y'] = by\n",
    "fields['B']['z'] = bz\n",
    "\n",
    "# All variables with _d at the and are for device variables\n",
    "print(\"allocate/copy field/data arrays to device\")\n",
    "ex_d = cuda.to_device(ex)\n",
    "ey_d = cuda.to_device(ey)\n",
    "ez_d = cuda.to_device(ez)\n",
    "bx_d = cuda.to_device(bx)\n",
    "by_d = cuda.to_device(by)\n",
    "bz_d = cuda.to_device(bz)\n",
    "\n",
    "charge_d = cuda.to_device(charge)\n",
    "xpos_d = cuda.to_device(xpos)\n",
    "ypos_d = cuda.to_device(ypos)\n",
    "zpos_d = cuda.to_device(zpos)\n",
    "momentumx_d = cuda.to_device(momentumx)\n",
    "momentumy_d = cuda.to_device(momentumy)\n",
    "momentumz_d = cuda.to_device(momentumz)\n",
    "mass_d = cuda.to_device(mass)\n",
    "weightings_d = cuda.to_device(weightings)\n",
    "chunk_offset_d = cuda.to_device(chunk_offset)\n",
    "\n",
    "print(\"\\nstart of field calculation time:\", time.ctime())\n",
    "starttime = time.time()\n",
    "\n",
    "cudaFunc[griddim, blockdim](ex_d, ey_d, ez_d, bx_d, by_d, bz_d, charge_d, xpos_d, ypos_d, zpos_d, momentumx_d, momentumy_d, momentumz_d, mass_d, weightings_d, xdim, ydim, zdim, particleCount, chunk_offset_d)\n",
    "cuda.synchronize()\n",
    "\n",
    "exeTime = time.time()-starttime\n",
    "print(\"time: {:.5}\".format( exeTime ), \"s\")\n",
    "print(\"avgTime per particle per cell:\", exeTime / particleCount / (xdim*ydim*zdim), \"s/(particle*cell)\")\n",
    "\n",
    "\n",
    "print(\"\\nget field arrays from device\", time.ctime())\n",
    "ex_d.copy_to_host(ex)\n",
    "ey_d.copy_to_host(ey)\n",
    "ez_d.copy_to_host(ez)\n",
    "bx_d.copy_to_host(bx)\n",
    "by_d.copy_to_host(by)\n",
    "bz_d.copy_to_host(bz)\n",
    "print(\"field arrays copied from device to host\", time.ctime())\n",
    "\n",
    "# delete device variables, no longer needed after the parallel computation\n",
    "del charge_d\n",
    "del xpos_d\n",
    "del ypos_d\n",
    "del zpos_d\n",
    "del momentumx_d\n",
    "del momentumy_d\n",
    "del momentumz_d\n",
    "del mass_d\n",
    "del weightings_d\n",
    "\n",
    "# write the calculate chunk of the field \n",
    "outputIteration.meshes['E']['x'].store_chunk(ex.reshape(xdim, ydim, zdim), chunk_offset, chunk_size)\n",
    "outputIteration.meshes['E']['y'].store_chunk(ey.reshape(xdim, ydim, zdim), chunk_offset, chunk_size)\n",
    "outputIteration.meshes['E']['z'].store_chunk(ez.reshape(xdim, ydim, zdim), chunk_offset, chunk_size)\n",
    "outputIteration.meshes['B']['x'].store_chunk(bx.reshape(xdim, ydim, zdim), chunk_offset, chunk_size)\n",
    "outputIteration.meshes['B']['y'].store_chunk(by.reshape(xdim, ydim, zdim), chunk_offset, chunk_size)\n",
    "outputIteration.meshes['B']['z'].store_chunk(bz.reshape(xdim, ydim, zdim), chunk_offset, chunk_size)\n",
    "writeSeries.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b64541f-a9b6-43f3-845d-4de3b19676ab",
   "metadata": {},
   "source": [
    "## When finished with all field chunks\n",
    "you can write the other data to the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c88f2d81-6d83-49a9-9ade-de66d5fbaf26",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "write()\n",
    "print(\"data written\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e358894-7089-4811-a8d0-5eab7e741b83",
   "metadata": {},
   "source": [
    "# Visualization of the fields if necessary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de532207-001b-46bb-9127-092d7784c6b6",
   "metadata": {},
   "source": [
    "and other stuff, not realy documented with comments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3188b42-1a92-43e7-ae7e-d992bcda51ab",
   "metadata": {},
   "source": [
    "## absolute field values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49779d2f-4d44-4e08-94d4-58ecfa17ef9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# absolute values of the fields\n",
    "ef = np.sqrt(ex**2+ey**2+ez**2)\n",
    "bf = np.sqrt(bx**2+by**2+bz**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89cccdc8-d98b-4aab-9f79-31c9d60abf78",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "depth = 400\n",
    "plt.imshow((ef.reshape(zdim, ydim, xdim)[depth].T))\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a219a4-526f-4282-8447-8a01fab1dd48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8d129ada-85fc-4a09-a2d0-55f5a80e4f22",
   "metadata": {},
   "source": [
    "## show particle positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca4b9f8-c549-4c05-bbf4-bc88a14ca742",
   "metadata": {},
   "outputs": [],
   "source": [
    "figsize(15,15)\n",
    "a = np.histogram2d(xpos, ypos, weights=weightings, bins=[np.linspace(0, xdim, xdim+1), np.linspace(0, ydim, ydim+1)] )\n",
    "imshow(a[0])\n",
    "xlabel(\"y cells\")\n",
    "ylabel(\"x cells\")\n",
    "show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc588cc-7f91-4c87-a55b-f5f51e6471b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "del ex_d\n",
    "del ey_d\n",
    "del ez_d\n",
    "del bx_d\n",
    "del by_d\n",
    "del bz_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "573c2aaf-6245-46c6-bee2-a68b573c6acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "del writeSeries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e7d86df-8cfe-4534-90ca-65f04dd692f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9492bf31-2cce-4a57-96c4-f58151677718",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f6acf4-3e11-455b-a47a-56d047c7dfcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f40001f6-41ac-425b-afd3-ffe2d9f2cb0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "v = 5e-4\n",
    "figure = plt.figure(figsize=(10,10))\n",
    "plt.imshow(fields['B']['z'].reshape(768, 512, 768)[500].T, vmin=-v, vmax=v)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "223c190d-dbc4-4d2d-9ccb-f8f3a696907a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca8cb596-6abb-4257-8e73-881aea9b7717",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
